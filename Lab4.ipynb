{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Binary classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 2])\n",
      "torch.Size([8, 1])\n",
      "epoch: 0 cost: 0.693147\n",
      "epoch: 1 cost: 0.672145\n",
      "epoch: 2 cost: 0.657294\n",
      "epoch: 3 cost: 0.646757\n",
      "epoch: 4 cost: 0.639247\n",
      "epoch: 5 cost: 0.633865\n",
      "epoch: 6 cost: 0.629987\n",
      "epoch: 7 cost: 0.627179\n",
      "epoch: 8 cost: 0.625135\n",
      "epoch: 9 cost: 0.623641\n",
      "epoch: 10 cost: 0.622544\n",
      "epoch: 11 cost: 0.621735\n",
      "epoch: 12 cost: 0.621136\n",
      "epoch: 13 cost: 0.620691\n",
      "epoch: 14 cost: 0.620359\n",
      "epoch: 15 cost: 0.620110\n",
      "epoch: 16 cost: 0.619922\n",
      "epoch: 17 cost: 0.619779\n",
      "epoch: 18 cost: 0.619671\n",
      "epoch: 19 cost: 0.619587\n",
      "epoch: 20 cost: 0.619522\n",
      "epoch: 21 cost: 0.619470\n",
      "epoch: 22 cost: 0.619429\n",
      "epoch: 23 cost: 0.619396\n",
      "epoch: 24 cost: 0.619368\n",
      "epoch: 25 cost: 0.619345\n",
      "epoch: 26 cost: 0.619325\n",
      "epoch: 27 cost: 0.619308\n",
      "epoch: 28 cost: 0.619292\n",
      "epoch: 29 cost: 0.619277\n",
      "epoch: 30 cost: 0.619264\n",
      "epoch: 31 cost: 0.619251\n",
      "epoch: 32 cost: 0.619239\n",
      "epoch: 33 cost: 0.619228\n",
      "epoch: 34 cost: 0.619216\n",
      "epoch: 35 cost: 0.619205\n",
      "epoch: 36 cost: 0.619194\n",
      "epoch: 37 cost: 0.619183\n",
      "epoch: 38 cost: 0.619173\n",
      "epoch: 39 cost: 0.619162\n",
      "epoch: 40 cost: 0.619152\n",
      "epoch: 41 cost: 0.619141\n",
      "epoch: 42 cost: 0.619131\n",
      "epoch: 43 cost: 0.619120\n",
      "epoch: 44 cost: 0.619110\n",
      "epoch: 45 cost: 0.619100\n",
      "epoch: 46 cost: 0.619089\n",
      "epoch: 47 cost: 0.619079\n",
      "epoch: 48 cost: 0.619069\n",
      "epoch: 49 cost: 0.619058\n",
      "epoch: 50 cost: 0.619048\n",
      "epoch: 51 cost: 0.619038\n",
      "epoch: 52 cost: 0.619027\n",
      "epoch: 53 cost: 0.619017\n",
      "epoch: 54 cost: 0.619007\n",
      "epoch: 55 cost: 0.618996\n",
      "epoch: 56 cost: 0.618986\n",
      "epoch: 57 cost: 0.618976\n",
      "epoch: 58 cost: 0.618965\n",
      "epoch: 59 cost: 0.618955\n",
      "epoch: 60 cost: 0.618945\n",
      "epoch: 61 cost: 0.618935\n",
      "epoch: 62 cost: 0.618924\n",
      "epoch: 63 cost: 0.618914\n",
      "epoch: 64 cost: 0.618904\n",
      "epoch: 65 cost: 0.618893\n",
      "epoch: 66 cost: 0.618883\n",
      "epoch: 67 cost: 0.618873\n",
      "epoch: 68 cost: 0.618863\n",
      "epoch: 69 cost: 0.618852\n",
      "epoch: 70 cost: 0.618842\n",
      "epoch: 71 cost: 0.618832\n",
      "epoch: 72 cost: 0.618821\n",
      "epoch: 73 cost: 0.618811\n",
      "epoch: 74 cost: 0.618801\n",
      "epoch: 75 cost: 0.618791\n",
      "epoch: 76 cost: 0.618780\n",
      "epoch: 77 cost: 0.618770\n",
      "epoch: 78 cost: 0.618760\n",
      "epoch: 79 cost: 0.618750\n",
      "epoch: 80 cost: 0.618739\n",
      "epoch: 81 cost: 0.618729\n",
      "epoch: 82 cost: 0.618719\n",
      "epoch: 83 cost: 0.618709\n",
      "epoch: 84 cost: 0.618698\n",
      "epoch: 85 cost: 0.618688\n",
      "epoch: 86 cost: 0.618678\n",
      "epoch: 87 cost: 0.618668\n",
      "epoch: 88 cost: 0.618657\n",
      "epoch: 89 cost: 0.618647\n",
      "epoch: 90 cost: 0.618637\n",
      "epoch: 91 cost: 0.618627\n",
      "epoch: 92 cost: 0.618617\n",
      "epoch: 93 cost: 0.618606\n",
      "epoch: 94 cost: 0.618596\n",
      "epoch: 95 cost: 0.618586\n",
      "epoch: 96 cost: 0.618576\n",
      "epoch: 97 cost: 0.618565\n",
      "epoch: 98 cost: 0.618555\n",
      "epoch: 99 cost: 0.618545\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "\n",
    "x_data = [[80,220],[75,167],[86,210],[110,330],[95,280],[67,190],[79,210],[98,250]]\n",
    "y_data = [[1],[0],[1],[1],[1],[0],[0],[1]]\n",
    "\n",
    "x_train = torch.FloatTensor(x_data)\n",
    "y_train = torch.FloatTensor(y_data)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "W = torch.zeros((2,1), requires_grad = True)\n",
    "b = torch.zeros(1,requires_grad = True)\n",
    "\n",
    "optimizer = optim.SGD([W,b], lr = 0.00001)\n",
    "\n",
    "for e in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = 1/(1+torch.exp(-(x_train.matmul(W)+b)))\n",
    "    loss = -(y_train * torch.log(hypothesis) + (1-y_train) * torch.log(1-hypothesis))\n",
    "    #cost = loss.mean()\n",
    "    cost = F.binary_cross_entropy(hypothesis, y_train)  # you can use hypothesis directly\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    print(\"epoch: %d cost: %f\" %(e,cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Multi-class classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_data = [[80]]"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
